{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLG-For-Conversational-Q&A.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3Oil1FXVnIg"
      },
      "outputs": [],
      "source": [
        "!pip install transformers \n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLG For Conversational Q&A\n",
        "**Goal:**\n",
        "\n",
        "Goal was to assemble a NLP pipeline which is able to answer a question and providing a longer text response (usually one whole sentence) which uses words used in question for conversational closed domain q&a. \n",
        "\n",
        "**Approach:**\n",
        "\n",
        "1. pretrained BERT Q&A model for question answer answering which generates short answers (keywords)\n",
        "2. finetune pretrained T5 model to generate longer answers which also takes the question into consideration from questions and keyword answers to suit a conversational environment\n",
        "\n",
        "**How To Finetune T5?**\n",
        "\n",
        "Finetuning via few shot learning. Meaning T5 is able to learn a new task with few training data because T5 has already knowledge about the language. Training data example: `q: Bis wann muss ich meine Wohnung nach Einzug anmelden? a: innerhalb von 14 Tagen` -> `Sie müssen Ihre Wohnung innerhalb von 14 Tagen anmelden.`\n",
        "\n",
        "\n",
        "**Results & Findings**\n",
        "* BERT's ability to find answers is acceptable. BERT is not able to find more complex answers, especially involving logical functions like AND or OR. \n",
        "* Even though T5 was finetuned only on 20 domain examples it does generate good quality responses for unseen data. The Problem is that the best generated response is not always the highest ranked text thus a human is still needed to pick the best response. One way to fix it is to probably train it with more data.\n",
        "* Practical implementation and integration in Rasa: high RAM requirements to load two relative large models -> probably does not run on computers with less than 8GB of RAM together with the rest of Rasa; high interference time (5-6s per question without Rasa NLU and without GPU acceleration) -> less suitable for live chat\n"
      ],
      "metadata": {
        "id": "XzMZw2KeQYep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetune T5 via Few Shot Learning\n"
      ],
      "metadata": {
        "id": "cPISWqEkThxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")"
      ],
      "metadata": {
        "id": "kBbT9qgN1j2G"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained('t5-base')"
      ],
      "metadata": {
        "id": "KBYUKr88emWL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer\n",
        "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "optimizer_grouped_parameters = [\n",
        "    {\n",
        "        \"params\": [p for n, p in t5_model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "        \"weight_decay\": 0.0,\n",
        "    },\n",
        "    {\n",
        "        \"params\": [p for n, p in t5_model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "        \"weight_decay\": 0.0,\n",
        "    },\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-4, eps=1e-8)"
      ],
      "metadata": {
        "id": "rd1YgRB-eop_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./t5-train.csv', sep=';')"
      ],
      "metadata": {
        "id": "WSVgfKoMpPAM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "t5_model.to(device)"
      ],
      "metadata": {
        "id": "5TWBfB9zKMIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t5_model.train()\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print (\"epoch: \", epoch)\n",
        "  for index, row in df.iterrows():\n",
        "    input_sent = \"q: \" + row['question'] + \" a: \" + row['short']\n",
        "    ouput_sent = row['long']\n",
        "\n",
        "    tokenized_inp = tokenizer.encode_plus(input_sent,  max_length=96, pad_to_max_length=True,return_tensors=\"pt\")\n",
        "    tokenized_output = tokenizer.encode_plus(ouput_sent, max_length=96, pad_to_max_length=True,return_tensors=\"pt\")\n",
        "\n",
        "    input_ids  = tokenized_inp[\"input_ids\"].to(device)\n",
        "    attention_mask = tokenized_inp[\"attention_mask\"].to(device)\n",
        "\n",
        "    lm_labels= tokenized_output[\"input_ids\"].to(device)\n",
        "    decoder_attention_mask=  tokenized_output[\"attention_mask\"].to(device)\n",
        "\n",
        "    # the forward function automatically creates the correct decoder_input_ids\n",
        "    output = t5_model(input_ids=input_ids, labels=lm_labels,decoder_attention_mask=decoder_attention_mask,attention_mask=attention_mask)\n",
        "    loss = output[0]\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "8h6vCPiFetYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t5_model.save_pretrained(\"./t5/\", push_to_hub=False)"
      ],
      "metadata": {
        "id": "cKMlRqoY8b0g"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q&A NLG Pipeline "
      ],
      "metadata": {
        "id": "Dv_aU4v_geX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, T5Tokenizer, T5ForConditionalGeneration "
      ],
      "metadata": {
        "id": "DAUjVu-PHzfZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_pipeline = pipeline(\n",
        "    \"question-answering\",\n",
        "    model=\"Sahajtomar/GBERTQnA\",\n",
        "    tokenizer=\"Sahajtomar/GBERTQnA\"\n",
        ")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"./t5/\")"
      ],
      "metadata": {
        "id": "mj5EUw0qQOx3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context=\"Mit einem Führungszeugnis können Sie nachweisen, dass Sie nicht vorbestraft sind. Führungszeugnisse unterscheidet man danach, ob sie bestimmt sind für private Zwecke (zum Beispiel für Ihren Arbeitgeber) oder für Behörden (sogenanntes „behördliches Führungszeugnis“, auch „Führungszeugnis zur Vorlage bei einer Behörde“). Außerdem gibt es unterschiedliche Arten von Führungszeugnissen nämlich, ein einfaches Führungszeugnis und ein erweitertes Führungszeugnis. Angehörige anderer EU-Staaten erhalten ein europäisches Führungszeugnis. Europäische Führungszeugnisse enthalten auch Strafregister-Einträge aus Ihrem Heimatland. Das Führungszeugnis wird erstellt vom Bundesamt für Justiz in Bonn (Bundeszentralregister). Wird das Führungszeugnis für private Zwecke benötigt, erhalten Sie es postalisch an Ihre Anschrift übersandt; eines für behördliche Zwecke geht direkt an die Behörde.\"\n",
        "question=\"Was stehet in dem Europäischen Führungszeugnis?\"\n",
        "question"
      ],
      "metadata": {
        "id": "QOWdxsoZMemQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ad494790-7c90-4f16-c1ec-c75b6450c7d6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Was stehet in dem Europäischen Führungszeugnis?'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_res = qa_pipeline({'context': context, 'question': question})['answer']\n",
        "qa_res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ve7ak08SMNGM",
        "outputId": "3967de39-23eb-4414-fef6-2f9127e55187"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Strafregister-Einträge'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"q: \" + question + \" a: \" + qa_res\n",
        "tokenized = tokenizer.encode_plus(input, return_tensors=\"pt\")\n",
        "\n",
        "input_ids = tokenized[\"input_ids\"]\n",
        "attention_mask = tokenized[\"attention_mask\"]\n",
        "\n",
        "model.eval()\n",
        "beam_outputs = model.generate(\n",
        "    input_ids=input_ids,attention_mask=attention_mask,\n",
        "    max_length=64,\n",
        "    early_stopping=True,\n",
        "    num_beams=10,\n",
        "    num_return_sequences=5,\n",
        "    no_repeat_ngram_size=2\n",
        ")\n",
        "\n",
        "for beam_output in beam_outputs:\n",
        "    sent = tokenizer.decode(beam_output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "    print (sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgQcIBQJQTFN",
        "outputId": "f97eed88-5375-4ab4-d783-875a6c1b35df"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Der Europäische Führungszeugnis wird durch Strafregister-Einträge ersetzt.\n",
            "Das Europäische Führungszeugnis wird vom Strafregister-Einträge begleitet.\n",
            "Das Europäische Führungszeugnis beinhaltet Ihre Strafregister-Einträge.\n",
            "Das Europäische Führungszeugnis wird durch Strafregister-Einträge ersetzt.\n",
            "Der Europäische Führungszeugnis wird vom Strafregister-Einträge begleitet.\n"
          ]
        }
      ]
    }
  ]
}