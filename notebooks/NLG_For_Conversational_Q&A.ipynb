{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3Oil1FXVnIg"
      },
      "outputs": [],
      "source": [
        "# restart vm afer installation of 'sentencepiece'\n",
        "!pip install transformers \n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzMZw2KeQYep"
      },
      "source": [
        "# NLG For Conversational Q&A\n",
        "**Goal:**\n",
        "\n",
        "Goal was to assemble a NLP pipeline which is able to answer a question and providing a longer text response (usually one whole sentence) which uses words used in question for conversational closed domain q&a. \n",
        "\n",
        "**Approach:**\n",
        "\n",
        "1. pretrained BERT Q&A model for question answer answering which generates short answers (keywords)\n",
        "2. finetune pretrained T5 model to generate longer answers which also takes the test of the question into consideration aswell as the keyword answers to suit a conversational environment\n",
        "\n",
        "**How To Finetune T5?**\n",
        "\n",
        "Finetuning via few shot learning. Meaning T5 is able to learn a new task with few training data because T5 has already knowledge about the language. Training data example: `q: Bis wann muss ich meine Wohnung nach Einzug anmelden? a: innerhalb von 14 Tagen` -> `Sie müssen Ihre Wohnung innerhalb von 14 Tagen anmelden.`\n",
        "\n",
        "\n",
        "**Results & Findings**\n",
        "* BERT's ability to find answers is acceptable but not great. BERT is not able to find more complex answers, especially involving logical functions like AND or OR. \n",
        "* Even though T5 was finetuned only on 20 domain examples it does generate good quality responses for unseen data. The Problem is that the best generated response is not always the highest ranked text thus a human is still needed to pick the best response. One way to fix it is to probably train it with more data.\n",
        "* Practical implementation and integration in Rasa: high RAM requirements to load two relative large models -> probably does not run on computers with less than 8GB of RAM together with the rest of Rasa; high interference time (5-6s per question without Rasa NLU and without GPU acceleration) -> less suitable for live chat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rNJMpOlHxxA"
      },
      "source": [
        "**Update 23.01.2022:**\n",
        "* Substitution of BERT; ELECTRA is now used for question answering\n",
        "* ELECTRA outperforms BERT in the Q&A task and it can also handel more complex contexts containing AND or OR \n",
        "* ELECTRA used less space than BERT \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPISWqEkThxX"
      },
      "source": [
        "## Finetune T5 via Few Shot Learning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kBbT9qgN1j2G"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "from transformers import AdamW, T5ForConditionalGeneration, T5Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KBYUKr88emWL"
      },
      "outputs": [],
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained('t5-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WSVgfKoMpPAM"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "df = pd.read_csv('./t5-train.csv', sep=';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rd1YgRB-eop_"
      },
      "outputs": [],
      "source": [
        "# optimizer\n",
        "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "optimizer_grouped_parameters = [\n",
        "    {\n",
        "        \"params\": [p for n, p in t5_model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "        \"weight_decay\": 0.0,\n",
        "    },\n",
        "    {\n",
        "        \"params\": [p for n, p in t5_model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "        \"weight_decay\": 0.0,\n",
        "    },\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-4, eps=1e-8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TWBfB9zKMIe"
      },
      "outputs": [],
      "source": [
        "# enable gpu acceleration if available\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "t5_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8h6vCPiFetYH",
        "outputId": "7a944d34-6f4e-4dff-d266-6ce454514412"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 0.0192: 100%|██████████| 20/20 [01:00<00:00,  3.00s/it]\n"
          ]
        }
      ],
      "source": [
        "# sets model to train mode\n",
        "t5_model.train()\n",
        "\n",
        "epochs = 20\n",
        "with tqdm(total = epochs) as epoch_pbar:\n",
        "  for epoch in range(epochs):\n",
        "    acc_loss = 0\n",
        "    idx = 0\n",
        "    for index, row in df.iterrows():\n",
        "      # get raw train data and format it\n",
        "      input_sent = \"q: \" + row['question'] + \" a: \" + row['short']\n",
        "      ouput_sent = row['long']\n",
        "\n",
        "      # tokenize text input and output (label)\n",
        "      tokenized_input = tokenizer.encode_plus(input_sent, max_length=128, padding='max_length', return_tensors=\"pt\")\n",
        "      tokenized_output = tokenizer.encode_plus(ouput_sent, max_length=64, padding='max_length', return_tensors=\"pt\")\n",
        "\n",
        "      # get embendings for inputs and labels\n",
        "      input_ids = tokenized_input[\"input_ids\"].to(device)\n",
        "      attention_mask = tokenized_input[\"attention_mask\"].to(device)\n",
        "      labels = tokenized_output[\"input_ids\"].to(device)\n",
        "      decoder_attention_mask = tokenized_output[\"attention_mask\"].to(device)\n",
        "\n",
        "      # the forward function automatically creates the correct decoder_input_ids\n",
        "      output = t5_model(\n",
        "          input_ids = input_ids, \n",
        "          labels = labels,\n",
        "          decoder_attention_mask = decoder_attention_mask,\n",
        "          attention_mask = attention_mask\n",
        "      )\n",
        "\n",
        "      # get train loss\n",
        "      loss = output[0]\n",
        "      acc_loss += loss\n",
        "      idx += 1\n",
        "\n",
        "      # backpropagation \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "    # update progress bar\n",
        "    avg_loss = acc_loss / (idx + 1)\n",
        "    desc = f'loss {avg_loss:.4f}'\n",
        "    epoch_pbar.set_description(desc)\n",
        "    epoch_pbar.update(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cKMlRqoY8b0g"
      },
      "outputs": [],
      "source": [
        "t5_model.save_pretrained(\"./t5/\", push_to_hub=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv_aU4v_geX6"
      },
      "source": [
        "## Q&A NLG Pipeline "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DAUjVu-PHzfZ"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, T5Tokenizer, T5ForConditionalGeneration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mj5EUw0qQOx3"
      },
      "outputs": [],
      "source": [
        "qa_pipeline = pipeline(\"question-answering\",\n",
        "                       model=\"deepset/gelectra-base-germanquad\",\n",
        "                       tokenizer=\"deepset/gelectra-base-germanquad\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"./t5/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QOWdxsoZMemQ",
        "outputId": "01f7f399-f646-4224-b497-e1e15938c895"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Was stehet in dem Europäischen Führungszeugnis?'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context=\"Mit einem Führungszeugnis können Sie nachweisen, dass Sie nicht vorbestraft sind. Führungszeugnisse unterscheidet man danach, ob sie bestimmt sind für private Zwecke (zum Beispiel für Ihren Arbeitgeber) oder für Behörden (sogenanntes „behördliches Führungszeugnis“, auch „Führungszeugnis zur Vorlage bei einer Behörde“). Außerdem gibt es unterschiedliche Arten von Führungszeugnissen nämlich, ein einfaches Führungszeugnis und ein erweitertes Führungszeugnis. Angehörige anderer EU-Staaten erhalten ein europäisches Führungszeugnis. Europäische Führungszeugnisse enthalten auch Strafregister-Einträge aus Ihrem Heimatland. Das Führungszeugnis wird erstellt vom Bundesamt für Justiz in Bonn (Bundeszentralregister). Wird das Führungszeugnis für private Zwecke benötigt, erhalten Sie es postalisch an Ihre Anschrift übersandt; eines für behördliche Zwecke geht direkt an die Behörde.\"\n",
        "question=\"Was stehet in dem Europäischen Führungszeugnis?\"\n",
        "question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ve7ak08SMNGM",
        "outputId": "d49384ac-4413-40cb-816c-21e0d4810d11"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Strafregister-Einträge aus Ihrem Heimatland'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qa_res = qa_pipeline({'context': context, 'question': question})['answer']\n",
        "qa_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgQcIBQJQTFN",
        "outputId": "79bc8650-1f6c-4a10-8ff2-e8fd0041a7d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Das Europäische Führungszeugnis beinhaltet Strafregister-Einträge aus Ihrem Heimatland.\n",
            "Was stehet in dem Europäischen Führungszeugnis aus Ihrem Heimatland?\n",
            "Sie erhalten in dem Europäischen Führungszeugnis einträge aus Ihrem Heimatland.\n",
            "Strafregister-Einträge aus Ihrem Heimatland.\n",
            "Das Strafregister-Einträge aus Ihrem Heimatland sind.\n"
          ]
        }
      ],
      "source": [
        "input = \"q: \" + question + \" a: \" + qa_res\n",
        "tokenized = tokenizer.encode_plus(input, return_tensors=\"pt\")\n",
        "\n",
        "input_ids = tokenized[\"input_ids\"]\n",
        "attention_mask = tokenized[\"attention_mask\"]\n",
        "\n",
        "model.eval()\n",
        "beam_outputs = model.generate(input_ids=input_ids,\n",
        "                              attention_mask=attention_mask,\n",
        "                              max_length=64,\n",
        "                              early_stopping=True,\n",
        "                              num_beams=10,\n",
        "                              num_return_sequences=5,\n",
        "                              no_repeat_ngram_size=2)\n",
        "\n",
        "for beam_output in beam_outputs:\n",
        "    sent = tokenizer.decode(beam_output,\n",
        "                            skip_special_tokens=True,\n",
        "                            clean_up_tokenization_spaces=True)\n",
        "    print(sent)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "NLG-For-Conversational-Q&A.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
